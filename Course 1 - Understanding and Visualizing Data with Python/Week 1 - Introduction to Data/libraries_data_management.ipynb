{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPScbsDWhjjS"
   },
   "source": [
    "# Python Libraries\n",
    "\n",
    "Python, like other programming languages, has an abundance of additional modules or libraries that augument the base framework and functionality of the language.\n",
    "\n",
    "Think of a library as a collection of functions that can be accessed to complete certain programming tasks without having to write your own algorithm.\n",
    "\n",
    "For this course, we will focus primarily on the following libraries:\n",
    "\n",
    "* **Numpy** is a library for working with arrays of data.\n",
    "\n",
    "* **Pandas** provides high-performance, easy-to-use data structures and data analysis tools.\n",
    "\n",
    "* **Scipy** is a library of techniques for numerical and scientific computing.\n",
    "\n",
    "* **Matplotlib** is a library for making graphs.\n",
    "\n",
    "* **Seaborn** is a higher-level interface to Matplotlib that can be used to simplify many graphing tasks.\n",
    "\n",
    "* **Statsmodels** is a library that implements many statistical techniques.\n",
    "\n",
    "# Documentation\n",
    "\n",
    "Reliable and accesible documentation is an absolute necessity when it comes to knowledge transfer of programming languages.  Luckily, python provides a significant amount of detailed documentation that explains the ins and outs of the language syntax, libraries, and more.  \n",
    "\n",
    "Understanding how to read documentation is crucial for any programmer as it will serve as a fantastic resource when learning the intricacies of python.\n",
    "\n",
    "Here is the link to the documentation of the python standard library: [Python Standard Library](https://docs.python.org/3/library/index.html#library-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b9FN-daXhjjT"
   },
   "source": [
    "### Importing Libraries\n",
    "\n",
    "When using Python, you must always begin your scripts by importing the libraries that you will be using. \n",
    "\n",
    "The following statement imports the numpy and pandas library, and gives them abbreviated names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRwVhX-YhjjU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oG4uoyAhjjX"
   },
   "source": [
    "### Utilizing Library Functions\n",
    "\n",
    "After importing a library, its functions can then be called from your code by prepending the library name to the function name.  For example, to use the '`dot`' function from the '`numpy`' library, you would enter '`numpy.dot`'.  To avoid repeatedly having to type the libary name in your scripts, it is conventional to define a two or three letter abbreviation for each library, e.g. '`numpy`' is usually abbreviated as '`np`'.  This allows us to use '`np.dot`' instead of '`numpy.dot`'.  Similarly, the Pandas library is typically abbreviated as '`pd`'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fip4VOLMhjjY"
   },
   "source": [
    "The next cell shows how to call functions within an imported library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9S03bwnkhjja",
    "outputId": "f3a621eb-281b-4f96-b4a9-ca112e4f8604"
   },
   "outputs": [],
   "source": [
    "a = np.array([0,1,2,3,4,5,6,7,8,9,10]) \n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljjQpFYfhjje"
   },
   "source": [
    "As you can see, we used the mean() function within the numpy library to calculate the mean of the numpy 1-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "auNcbdxVhjjf"
   },
   "source": [
    "# Data Management\n",
    "\n",
    "Data management is a crucial component to statistical analysis and data science work.  The following code will show how to import data via the pandas library, view your data, and transform your data.\n",
    "\n",
    "The main data structure that Pandas works with is called a **Data Frame**.  This is a two-dimensional table of data in which the rows typically represent cases (e.g. Cartwheel Contest Participants), and the columns represent variables.  Pandas also has a one-dimensional data structure called a **Series** that we will encounter when accesing a single column of a Data Frame.\n",
    "\n",
    "Pandas has a variety of functions named '`read_xxx`' for reading data in different formats.  Right now we will focus on reading '`csv`' files, which stands for comma-separated values. However the other file formats include excel, json, and sql just to name a few.\n",
    "\n",
    "This is a link to the .csv that we will be exploring in this tutorial: [Cartwheel Data](https://www.coursera.org/learn/understanding-visualization-data/resources/0rVxx) (Link goes to the dataset section of the Resources for this course)\n",
    "\n",
    "There are many other options to '`read_csv`' that are very useful.  For example, you would use the option `sep='\\t'` instead of the default `sep=','` if the fields of your data file are delimited by tabs instead of commas.  See [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) for the full documentation for '`read_csv`'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbGKgakihjjg"
   },
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXHHhj2jhjjg",
    "outputId": "af99e411-9c09-44aa-d619-553b2d2a5aa8"
   },
   "outputs": [],
   "source": [
    "# Store the url string that hosts our .csv file (note that this is a different url than in the video)\n",
    "url = \"Cartwheeldata.csv\"\n",
    "\n",
    "# Read the .csv file and store it as a pandas Data Frame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Output object type\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TrO3YWShjjl"
   },
   "source": [
    "### Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMgR30w4hjjl",
    "outputId": "9a269897-78a7-4380-9634-81d2d6165c2d"
   },
   "outputs": [],
   "source": [
    "# We can view our Data Frame by calling the head() function\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwcqqpCrhjjp"
   },
   "source": [
    "The head() function simply shows the first 5 rows of our Data Frame.  If we wanted to show the entire Data Frame we would simply write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clB7ZnfOhjjq",
    "outputId": "32b34b9e-c481-4c46-b443-488ac7097c55"
   },
   "outputs": [],
   "source": [
    "# Output entire Data Frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-F1DVbu4hjju"
   },
   "source": [
    "As you can see, we have a 2-Dimensional object where each row is an independent observation of our cartwheel data.\n",
    "\n",
    "To gather more information regarding the data, we can view the column names and data types of each column with the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEdgVYnDhjjv",
    "outputId": "3c4a5edc-e29d-4665-b58c-b2e9fa125442"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeR8lBkmhjjz"
   },
   "source": [
    "Lets say we would like to splice our data frame and select only specific portions of our data.  There are three different ways of doing so.\n",
    "\n",
    "1. .loc()\n",
    "2. .iloc()\n",
    "3. .ix()\n",
    "\n",
    "We will cover the .loc() and .iloc() splicing functions.\n",
    "\n",
    "### .loc()\n",
    ".loc() takes two single/list/range operator separated by ','. The first one indicates the row and the second one indicates columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpUEXXovhjj0",
    "outputId": "d4f26af0-9769-4fc1-c7ae-679e3dbf7c69"
   },
   "outputs": [],
   "source": [
    "# Return all observations of CWDistance\n",
    "df.loc[:,\"CWDistance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmZyHBk_hjj4",
    "outputId": "3d76358a-cd47-43bb-fd69-9f858f03add1"
   },
   "outputs": [],
   "source": [
    "# Select all rows for multiple columns, [\"CWDistance\", \"Height\", \"Wingspan\"]\n",
    "df.loc[:,[\"CWDistance\", \"Height\", \"Wingspan\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xi9U34Kwhjj8",
    "outputId": "e6413dbf-1ffe-4af4-e6b9-95e6d7c56dc0"
   },
   "outputs": [],
   "source": [
    "# Select few rows for multiple columns, [\"CWDistance\", \"Height\", \"Wingspan\"]\n",
    "df.loc[:9, [\"CWDistance\", \"Height\", \"Wingspan\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SACpAZDhjkA",
    "outputId": "79f0f222-85ed-4224-8242-69a8ae2742ff"
   },
   "outputs": [],
   "source": [
    "# Select range of rows for all columns\n",
    "df.loc[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALS06G3rhjkC"
   },
   "source": [
    "The .loc() function requires to arguments, the indices of the rows and the column names you wish to observe.\n",
    "\n",
    "In the above case **:** specifies all rows, and our column is **CWDistance**. df.loc[**:**,**\"CWDistance\"**]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DG7GYn4nhjkE"
   },
   "source": [
    "Now, let's say we only want to return the first 10 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKfblg4KhjkE",
    "outputId": "b3f4df29-8b8e-4a58-e69c-403dcd5a4dc5"
   },
   "outputs": [],
   "source": [
    "df.loc[:9, \"CWDistance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhluNGL1hjkI"
   },
   "source": [
    "### .iloc()\n",
    ".iloc() is integer based slicing, whereas .loc() used labels/column names. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6u1A-2drhjkJ",
    "outputId": "1eaf5856-74d9-4b2e-d8a4-93e163973cae"
   },
   "outputs": [],
   "source": [
    "df.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7U4Db6WhjkM",
    "outputId": "4068bbfc-c246-4847-bcd6-bce52656a71b"
   },
   "outputs": [],
   "source": [
    "df.iloc[1:5, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cot4DwdUhjkQ",
    "outputId": "52430bbe-8bab-48ac-b43d-deba59750797"
   },
   "outputs": [],
   "source": [
    "df.iloc[1:5, [\"Gender\", \"GenderGroup\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIekmzj6hjkT"
   },
   "source": [
    "We can view the data types of our data frame columns with by calling .dtypes on our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVvtjY7ghjkU",
    "outputId": "4cb2e4f1-19f7-46f8-b5f4-3d1d3b779c67"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxzHKNfKhjkX"
   },
   "source": [
    "The output indicates we have integers, floats, and objects with our Data Frame.\n",
    "\n",
    "We may also want to observe the different unique values within a specific column, lets do this for Gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brIC2kbKhjkZ",
    "outputId": "b3c7b6f1-3c6b-4145-ff19-a3437e298212"
   },
   "outputs": [],
   "source": [
    "# List unique values in the df['Gender'] column\n",
    "df.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Js4ikCVWhjkc",
    "outputId": "4cfbdf05-044e-4c56-9430-d392a589e9ee"
   },
   "outputs": [],
   "source": [
    "# Lets explore df[\"GenderGroup] as well\n",
    "df.GenderGroup.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3pqgpifhjkf"
   },
   "source": [
    "It seems that these fields may serve the same purpose, which is to specify male vs. female. Lets check this quickly by observing only these two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Oqj-XOghjkf",
    "outputId": "a02d15e9-bd6c-4f41-aa26-10dc0d8697e4"
   },
   "outputs": [],
   "source": [
    "# Use .loc() to specify a list of mulitple column names\n",
    "df.loc[:,[\"Gender\", \"GenderGroup\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0S7vCwphjkj"
   },
   "source": [
    "From eyeballing the output, it seems to check out.  We can streamline this by utilizing the groupby() and size() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNvUQetJhjkj",
    "outputId": "3eedb9e8-0d1a-4a1f-ff65-f7ee4a178c5e"
   },
   "outputs": [],
   "source": [
    "df.groupby(['Gender','GenderGroup']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bHLzOH2hjkn"
   },
   "source": [
    "This output indicates that we have two types of combinations. \n",
    "\n",
    "* Case 1: Gender = F & Gender Group = 1 \n",
    "* Case 2: Gender = M & GenderGroup = 2.  \n",
    "\n",
    "This validates our initial assumption that these two fields essentially portray the same information."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Introduction to Libraries and Data Management.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
